<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta charset="UTF-8">
    <title>Yongjun Choi</title>
    <meta name="author" content="Yongjun Choi">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- TODO: 파비콘 교체 -->
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <!-- 템플릿 CSS가 있으면 유지, 없으면 아래 style 블록 사용 -->
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    <style>
      /* 템플릿 CSS가 이미 있다면 이 style 블록은 삭제해도 됩니다 */
      body { -webkit-font-smoothing: antialiased; margin: 0; }
      h2 { margin: 24px 0 8px; }
      .name { font-size: 32px; font-weight: 700; }
      .muted { color:#666; }
      .pill { padding: 2px 8px; border-radius: 999px; border:1px solid #ddd; font-size:12px; }
      ul { margin-top: 6px; }
      ul.compact li { margin: 2px 0; }
      img.round { border-radius: 50%; }
      a { text-decoration: none; }
      table { border-collapse: separate; }
    </style>
  </head>

  <body>
    <table style="width:100%;max-width:900px;border:0;border-spacing:0;margin:0 auto;">
      <tbody>
        <tr>
          <td style="padding:0;">

            <!-- Header -->
            <table style="width:100%;border:0;border-spacing:0;margin:0 auto;">
              <tbody>
                <tr>
                  <td style="padding:2.5%;width:65%;vertical-align:middle;">
                    <p class="name" style="text-align:center;">Yongjun Choi</p>
                    <p style="text-align:center" class="muted">
                      3D Vision & Robotics Lab, UNIST<br>
                    </p>
                        <p>
                          Hello! I am a master's student in the 
                          <a href="https://unist.info/" target="_blank">3D Vision &amp; Robotics Lab</a> at UNIST, 
                          advised by Prof. <a href="https://unist.info/?page_id=194" target="_blank">Kyungdon Joo</a>.<br><br>

                          I was a visiting student in the CARTE, MIE, at the University of Toronto 
                          through the AI Convergence Program, supported by the IITP, Korean Government.<br><br>

                          My research has focused on 
                          <strong>3D scene understanding</strong>, 
                          <strong>image manipulation using generative model</strong>, 
                          <strong>video understanding</strong>, 
                          and <strong>visual–language modeling</strong>.
                          Currently, I'm expanding my research scope to encompass <strong>audio-visual modeling</strong>, where I am actively developing and evaluating multimodal learning frameworks.
                        </p>
                    <p>
                      Contact:
                      <a href="mailto:ccyjun123@unist.ac.kr" class="pill">ccyjun123@unist.ac.kr</a>
                    </p>

                    <p style="text-align:center">
                      <!-- TODO: 본인 링크로 교체 -->
                      <a href="data/CV_Yongjun.pdf" target="_blank">CV</a> &nbsp;/&nbsp;
                      <a href="https://www.linkedin.com/in/yongjun-choi-b84546279/" target="_blank">LinkedIn</a> &nbsp;/&nbsp;
                      <a href="https://github.com/beautifulchoi" target="_blank">GitHub</a>
                    </p>
                  </td>
                  <td style="padding:2.5%;width:35%;max-width:35%;">
                    <!-- TODO: 프로필 이미지 교체 -->
                    <a href="images/profile.jpg">
                      <img src="images/profile.jpg" alt="profile photo" style="width:100%;max-width:100%;object-fit:cover;" class="round">
                    </a>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Publications -->
            <table style="width:100%;border:0;border-spacing:0;margin:0 auto;">
              <tbody>
                <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <h2>Publications</h2>
                  </td>
                </tr>
              </tbody>
            </table>

            <table style="width:100%;border:0;border-spacing:0;margin:0 auto;">
              <tbody>

                <!-- Publication 1: AnyBald (WACV 2026) - Most Recent -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle;">
                    <img src="images/anybald_fig.jpg" width="300" alt="Diffusion-based Hair Removal">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:top;padding-left:20px;">
                    <span style="font-weight:600;">AnyBald: Toward Realistic Diffusion-Based Hair Removal In-the-Wild</span><br>
                    <strong>Yongjun Choi*</strong>, Seungoh Han*, Soomin Kim, Sumin Son, Mohsen Rohani, Edgar Maucourant, Dongbo Min, Kyungdon Joo<br>
                    <em>WACV 2026</em> &nbsp;·&nbsp; <span style="font-size:12px;color:#888;">*Equal contribution</span><br>
                    <a href="https://vision3d-lab.github.io/anybald/" target="_blank">[Project Page]</a><br>
                    <ul class="compact">
                      <li>Developed AnyBald, a mask-free diffusion-based framework for realistic hair removal in the wild.</li>
                      <li>Achieves natural bald manipulation while preserving facial identity, enabling robust performance across diverse real-world scenarios.</li>
                    </ul>
                  </td>
                </tr>

                <!-- Publication 2: RAC-VAD (Under Review) -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle;">
                    <img src="images/anycall_fig.jpg" width="300" alt="practical video anomaly detection system in mobile devices">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:top;padding-left:20px;">
                    <span style="font-weight:600;">RAC-VAD: Reference-Guided Temporal Alignment and Pairwise Comparison for Video Anomaly Detection in Display Inspection</span><br>
                    <strong>Yongjun Choi</strong>, Gyeongsu Cho, Jinhyeok Kim, Changsu Ha, Sanggyu Biern, Kyungdon Joo<br>
                    <em>Under review at IEEE TCSVT</em><br>
                    <ul class="compact">
                      <li>Video-based anomaly detection system for industrial display device inspection, capable of identifying defects during long-term multi-device operation.</li>
                      <li>Introduce two-stage based video alignment and comparison approach for robust, noise-resistant anomaly detection.</li>
                    </ul>
                  </td>
                </tr>

                <!-- Publication 3: Gomoku AI -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle;">
                    <img src="images/gomokuai.png" width="300" height="180" alt="Gomoku AI">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:top;padding-left:20px;">
                    <span style="font-weight:600;">Demonstrating a Vision-Based AI Robot for Strategic Board Games</span><br>
                    Taehwan Kim*, Dokeun Lee*, Seonghyeon Kim*, <strong>Yongjun Choi*</strong>, Sungjun Heo, Thi Thuy Ngan Duong, Kyungdon Joo, Namhun Kim, Jeong hwan Jeon, Hyemin Ahn<br>
                    <em>Technical Report</em> &nbsp;·&nbsp; <span style="font-size:12px;color:#888;">*Equal contribution</span><br>
                    <a href="https://sites.google.com/view/gomoku-robot/" target="_blank">[Project Page]</a><br>
                    <ul class="compact">
                      <li>Developed a low-cost human–robot interaction system for playing Gomoku, integrating real-time vision perception, RL-based decision-making, and robotic arm control.</li>
                      <li>Offers an affordable, real-world gaming experience that merges physical gameplay with intelligent decision-making.</li>
                    </ul>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Projects (핵심만 정리) -->
            <table style="width:100%;border:0;border-spacing:0;margin:0 auto;">
              <tbody>
                <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <h2>Selected Projects</h2>
                  </td>
                </tr>
              </tbody>
            </table>

            <table style="width:100%;border:0;border-spacing:0;margin:0 auto;">
              <tbody>
                <!-- Project 1: AnyBald (Most Recent) -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle;">
                    <img src="images/fig1_1.jpg" width="300" alt="Diffusion-based Hair Removal">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:top;padding-left:20px;">
                    <span style="font-weight:600;">Realistic Hair Removal and Reconstruction in Images</span><br>
                    <em>Research project (Working with Modiface) </em> &nbsp;·&nbsp; 2025
                    <ul class="compact">
                      <li>Developed a robust <b>hair removal framework</b> primarily designed for hair transfer applications, enabling realistic and consistent bald rendering across diverse scenarios.</li>
                      <li>Served as the <b>technical lead</b> in implementing the core diffusion-based model and proposing the initial data augmentation pipeline for robust training.</li>
                    </ul>
                  </td>
                </tr>

                <!-- Project 2: Detecting Anomalies -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle;">
                    <img src="images/anycall_fig.jpg" width="300" alt="practical video anomaly detection system in mobile devices">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:top;padding-left:20px;">
                    <span style="font-weight:600;">Detecting Anomalies from normal videos</span><br>
                    <em>Industrial project (funded by Samsung Electronics) </em> &nbsp;·&nbsp; 2024
                    <ul class="compact">
                      <li>Developed video anomaly detection system for industrial display inspection, built to ensure stable defect detection during long-term multi-device operation.</li>
                      <li>Served as the <b>technical lead</b>, spearheading the implementation of the core proposed method and conducting all major experiments.</li>
                    </ul>
                  </td>
                </tr>

                <!-- Project 3: Gomoku AI -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle;">
                    <img src="images/gomoku.png" width="300" height="180" alt="Gomoku AI">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:top;padding-left:20px;">
                    <span style="font-weight:600;">Gomoku AI: Demonstrating a Vision-Based AI Robot for Strategic Board Games</span><br>
                    <em>HRI course final project </em> &nbsp;·&nbsp; 2024
                    <ul class="compact">
                      <li>Built a vision-based human–robot interaction system for playing Gomoku, integrating real-time perception, AI decision-making, and robotic arm control.</li>
                      <li>Responsible for the entire <b>vision module</b>, developing the perception system that enables the robot to recognize and understand the full game state.</li>
                    </ul>
                  </td>
                </tr>

                <!-- Project 4: Lang-Grouping -->
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle;">
                    <img src="images/lang_grouping.PNG" width="300" height="180" alt="lang feature + 3dgs">
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:top;padding-left:20px;">
                    <span style="font-weight:600;">Lang-Grouping: Object-centric semantic grouping for better understanding 3D scenes</span><br>
                    <em>3D vision course final project</em> &nbsp;·&nbsp; 2024.04 – 2024.06
                    <ul class="compact">
                      <li>Object-level language–3D scene understanding framework, reducing inference time compared to LangSplat.</li>
                      <li>Propose an object-centric contrastive learning approach to enhance multi-view consistency for CLIP feature distillation in Gaussian Splatting.</li>
                    </ul>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Experience -->
            <table style="width:100%; border:0; border-spacing:0; margin:0 auto;">
              <tbody>
                <tr>
                  <td style="padding:20px; width:100%; vertical-align:middle;">
                    <h2>Experience</h2>
                  </td>
                </tr>
              </tbody>
            </table>

            <table style="width:100%; border:0; border-spacing:0; margin:0 auto;">
              <tbody>
                <tr>
                  <td style="padding:10px 20px;">
                    <ul style="list-style-type: none; padding-left: 0;">
                      
                      <li>
                        <strong>Visiting Student</strong>, University of Toronto (Jan 2025 – Jun 2025)
                        <ul style="list-style-type: circle; margin: 5px 0 15px 20px;">
                          <li>Special MEng student at MIE – completed 4 graduate-level courses with a GPA of 3.95/4.0</li>
                          <li>Industrial project with Modiface (Technical Leading)</li>
                        </ul>
                      </li>

                      <li>
                        <strong>Teaching Assistant</strong>, UNIST
                        <ul style="list-style-type: circle; margin: 5px 0 15px 20px;">
                          <li>AI Programming 2 (Sep 2024 – Dec 2024)</li>
                          <li>Kyungnam Novatus Academia (Jul 2024)</li>
                        </ul>
                      </li>

                      <li>
                        <strong>Research Assistant</strong>, 3D Vision &amp; Robotics Lab, UNIST (Mar 2024 – Aug 2026)
                        <ul style="list-style-type: circle; margin: 5px 0 15px 20px;">
                          <li>Video understanding, Language-guided 3D scene understanding</li>
                          <li>Industrial project with Samsung Electronics (Technical Leading)</li>
                        </ul>
                      </li>

                      <li>
                        <strong>Software Developer Intern</strong>, 
                        <a href="https://www.upsight.co.kr/" target="_blank">Upsight</a> 
                        (Jun 2023 – Aug 2023)
                        <ul style="list-style-type: circle; margin: 5px 0 15px 20px;">
                          <li>Contributed to developing a building crack detection model integrated into diagnostic processes</li>
                          <li>Contributed to the initial development of a landlord–tenant community app using Flutter</li>
                        </ul>
                      </li>

                      <li>
                        <strong>Undergraduate Research Intern</strong>, Computer Vision Lab, University of Seoul (Apr 2022 – Jul 2023)
                        <ul style="list-style-type: circle; margin: 5px 0 0 20px;">
                          <li>Mainly studied Masked Image Modeling (MIM)-based ViT and CAM methods</li>
                          <li>Built AI-based plant feature extractor for urban forest management mobile platform</li>
                        </ul>
                      </li>

                    </ul>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Awards & Scholarships -->
            <table style="width:100%; border:0; border-spacing:0; margin:0 auto;">
              <tbody>
                <tr>
                  <td style="padding:20px; width:100%; vertical-align:middle;">
                    
                    <!-- Awards & Honors -->
                    <h2>Awards &amp; Honors</h2>
                    <ul class="compact">
                      <li>
                        3rd place, AWS DeepRacer Competition, BigData Winter Camp (2022)
                      </li>
                      <li>
                        3rd place, Engineering Mathematics Competition, University of Seoul 
                        (awarded for <strong>three consecutive years</strong>: 2021, 2022, 2023)
                      </li>
                      <li>
                        3rd place, 
                        <a href="https://geomarket.kr/user/pst/view.do?pst_id=contest&pst_sn=99&search=VVppMi8vck9NWndkRnhPSGUySXZBZz09" target="_blank">
                          Spatial Convergence Big Data Idea Competition
                        </a> (2023) — Proposed and developed the company’s core concept as part of the team
                      </li>
                      <li>
                        3rd place, 
                        <a href="https://blog.naver.com/synctree/223269601512" target="_blank">
                          Syncathon Season 3 (AI development competition)
                        </a> — “finSET” (2023), serving as the team leader and project coordinator
                      </li>
                    </ul>

                    <!-- Scholarships -->
                    <h2>Scholarships</h2>
                    <ul class="compact">
                      <li>
                        <a href="https://scc.sogang.ac.kr/globalaiedu/curriculum.html" target="_blank">
                          AI Convergence Program Scholarship, IITP, Korean Government (2025)
                        </a>
                      </li>
                      <li>
                        <a href="https://woonhaefoundation.org/kor/main/main.html" target="_blank">
                          Wonhae Foundation (2023)
                        </a>
                      </li>
                      <li>
                        <a href="https://scholarship.uos.ac.kr/scholarship/notice/notice/view.do?brdDate=20221018&brdSeq=4&filSeq=&pageIndex=1&brdBbsseq=1&searchWrd=%EB%B3%B4%EC%9E%89&searchCnd=1&identified=anonymous&" target="_blank">
                          Boeing Korea (2022)
                        </a>
                      </li>
                      <li>
                        <a href="http://www.kochon.org/" target="_blank">
                          Kochon Foundation (2022)
                        </a>
                      </li>
                    </ul>

                  </td>
                </tr>
              </tbody>
            </table>

            <!-- External Experience
            <table style="width:100%;border:0;border-spacing:0;margin:0 auto;">
              <tbody>
                <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <h2>External Experience</h2>
                    <ul class="compact">
                      <li>Summer exchange student, EPITA, Paris, France (Jul 2019)</li>
                      <li>20th UOS SeoulMate, International Exchange Student Association (Jul – Dec 2021)</li>
                      <li>Peer Advocate, Seoul International Summer School Ambassador (Jun – Jul 2022)</li>
                      <li>GDSC Core Member, Data Analysis &amp; AI Group, University of Seoul (Sep 2022 – Jul 2023)</li>
                    </ul>
                  </td>
                </tr>
              </tbody>
            </table> -->

            <!-- Education -->
            <table style="width:100%;border:0;border-spacing:0;margin:0 auto;">
              <tbody>
                <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <h2>Education</h2>
                    <ul class="compact">
                      <li><strong>UNIST</strong> — M.S., Artificial Intelligence Graduate School (Expected Aug 2026), GPA: 4.03/4.3<br>
                        Advisor: Prof. Kyungdon Joo
                      </li>
                      <li><strong>University of Seoul</strong> — B.S., Electrical &amp; Computer Engineering (Feb 2024), GPA: 3.98/4.5 (Major 4.06/4.5)<br>
                        Advisor: Prof. Yongchul Kim
                      </li>
                    </ul>
                  </td>
                </tr>
              </tbody>
            </table>

            <!-- Footer -->
            <table style="width:100%;border:0;border-spacing:0;margin:0 auto;">
              <tbody>
                <tr>
                  <td style="padding:0;">
                    <br>
                    <p style="text-align:right;font-size:small;">
                      Template adapted from <a href="https://github.com/jonbarron/jonbarron_website" target="_blank">Jon Barron</a>.
                    </p>
                  </td>
                </tr>
              </tbody>
            </table>

          </td>
        </tr>
      </tbody>
    </table>
  </body>
</html>
